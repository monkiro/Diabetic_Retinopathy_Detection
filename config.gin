#input_pipeline
#processing_augmentation_oversampling
#processing_augmentation_oversampling.lb_path = 'D:\\DL_Lab_P1\\IDRID_dataset\\labels\\'
#processing_augmentation_oversampling.img_path = 'D:\\DL_Lab_P1\\IDRID_dataset\\images\\'
#processing_augmentation_oversampling.save_path = 'D:\\DL_Lab_P1\\dataset_processed\\'
#processing_augmentation_oversampling.amount = 2000

#image_pre
#preprocess.img_height = 28
#preprocess.img_width = 28

#tfrecord
#write_Tfrecord.save_path='D:\\DL_Lab_P1\\dataset_processed\\'
#load.data_dir='D:\\DL_Lab_P1\\dataset_processed\\'

#dataset
prepare.batch_size = 103
prepare.caching = False
load.name = 'idrid'
load.data_dir = 'D:\\DL_Lab_P1\\dataset_processed\\tensorflow_datasets\\'


# Training
Trainer.total_steps = 2000
Trainer.log_interval = 5
Trainer.ckpt_interval = 5
Trainer.acc=0
Trainer.alpha=0.25
Trainer.gamma=1.0
#Trainer.acc_highest = 0




#Basic_CNN(input_shape, base_filters, kernel_size, dense_units, dropout_rate, n_classes)
Basic_CNN.input_shape = (256, 256, 3) #256x256 pixels with 3 color channels (RGB).
Basic_CNN.base_filters =32
Basic_CNN.kernel_size=(3, 3)
Basic_CNN.dense_units=64
Basic_CNN.dropout_rate = 0.3
Basic_CNN.n_classes = 2

# fc_units = 32 # fully connected layer with 32 units
# filters_num = 32 # 32 filters in the first convolutional layer
# dropout_rate = 0.3 # prevent overfitting
# layer_dim = (1, 1, 1, 1) # 1x1 convolutional layers